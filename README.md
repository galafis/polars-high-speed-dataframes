# High-Speed DataFrames with Polars

![Python](https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python&logoColor=white)
![Polars](https://img.shields.io/badge/DataFrames-Polars-FF4500?style=for-the-badge&logo=polars&logoColor=white)
![Mermaid](https://img.shields.io/badge/Diagrams-Mermaid-orange?style=for-the-badge&logo=mermaid&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

---

## ðŸ‡§ðŸ‡· DataFrames de Alta Velocidade com Polars

Este repositÃ³rio explora e demonstra o uso da biblioteca **Polars para processamento de dados de alta performance**, focando em operaÃ§Ãµes com DataFrames. Polars Ã© uma alternativa robusta e extremamente rÃ¡pida ao Pandas, construÃ­da em Rust, que aproveita o paralelismo e a eficiÃªncia de memÃ³ria para lidar com grandes volumes de dados de forma otimizada. Ã‰ ideal para **anÃ¡lise exploratÃ³ria de dados, engenharia de features e pipelines de ETL** que exigem velocidade e escalabilidade.

### ðŸŽ¯ Objetivo

O principal objetivo deste projeto Ã© **fornecer exemplos prÃ¡ticos, benchmarks e tutoriais detalhados** para profissionais de dados que desejam migrar ou integrar Polars em seus fluxos de trabalho. SerÃ£o abordados desde os conceitos fundamentais de DataFrames em Polars atÃ© tÃ©cnicas avanÃ§adas de otimizaÃ§Ã£o, integraÃ§Ã£o com outras bibliotecas e comparaÃ§Ã£o de performance com outras ferramentas, com foco em **operaÃ§Ãµes de I/O eficientes, transformaÃ§Ãµes complexas e avaliaÃ§Ã£o lazy**.

### âœ¨ Destaques

- **I/O Otimizado**: DemonstraÃ§Ãµes de leitura e escrita eficientes de arquivos CSV e Parquet, aproveitando a performance do Polars para lidar com grandes volumes de dados.
- **TransformaÃ§Ãµes Complexas e ExpressÃµes AvanÃ§adas**: Exemplos de como aplicar transformaÃ§Ãµes de dados sofisticadas, incluindo agregaÃ§Ã£o, filtragem e criaÃ§Ã£o de novas colunas usando a poderosa sintaxe de expressÃµes do Polars.
- **AvaliaÃ§Ã£o Lazy (Lazy Evaluation)**: ExploraÃ§Ã£o do paradigma de avaliaÃ§Ã£o lazy do Polars, que permite a construÃ§Ã£o de planos de consulta otimizados, resultando em melhor performance e menor consumo de memÃ³ria.
- **OperaÃ§Ãµes de Join e CorrelaÃ§Ã£o**: DemonstraÃ§Ãµes de como realizar operaÃ§Ãµes de join entre DataFrames e calcular correlaÃ§Ãµes entre colunas, essenciais para anÃ¡lise de dados e engenharia de features.
- **Performance Excepcional**: Polars supera outras bibliotecas em velocidade e uso de memÃ³ria para operaÃ§Ãµes comuns de DataFrame, graÃ§as Ã  sua implementaÃ§Ã£o em Rust e paralelismo nativo.
- **API Intuitiva**: Exemplos que mostram a simplicidade e expressividade da API do Polars, facilitando a transiÃ§Ã£o para usuÃ¡rios de Pandas.
- **CÃ³digo Profissional**: Exemplos de cÃ³digo bem estruturados, seguindo as melhores prÃ¡ticas da indÃºstria, com foco em modularidade, reusabilidade e manutenibilidade.
- **DocumentaÃ§Ã£o Completa**: Cada exemplo Ã© acompanhado de documentaÃ§Ã£o detalhada, benchmarks e casos de uso prÃ¡ticos para facilitar a compreensÃ£o e a aplicaÃ§Ã£o.

### ðŸš€ BenefÃ­cios do Polars em AÃ§Ã£o

O Polars oferece uma sÃ©rie de vantagens que o tornam uma escolha superior para processamento de dados de alta performance. Este projeto ilustra como esses benefÃ­cios sÃ£o explorados:

1.  **Velocidade IncomparÃ¡vel:** ConstruÃ­do em Rust, o Polars aproveita a seguranÃ§a de memÃ³ria e a performance nativa para executar operaÃ§Ãµes de DataFrame em velocidades impressionantes, superando o Pandas em muitos cenÃ¡rios, especialmente em I/O e transformaÃ§Ãµes complexas.

2.  **Processamento Paralelo:** Utiliza todos os nÃºcleos da CPU disponÃ­veis por padrÃ£o, permitindo o processamento paralelo de dados sem a necessidade de configuraÃ§Ã£o manual complexa, o que Ã© evidente em operaÃ§Ãµes de agregaÃ§Ã£o e transformaÃ§Ã£o.

3.  **AvaliaÃ§Ã£o Lazy (Lazy Evaluation):** Permite a construÃ§Ã£o de planos de consulta otimizados, onde as operaÃ§Ãµes sÃ£o executadas apenas quando os resultados sÃ£o realmente necessÃ¡rios, economizando recursos e tempo, como demonstrado na funÃ§Ã£o `complex_lazy_evaluation`.

4.  **EficiÃªncia de MemÃ³ria:** Projetado para ser eficiente no uso de memÃ³ria, o Polars pode lidar com datasets maiores do que o Pandas em mÃ¡quinas com recursos limitados, tornando-o ideal para grandes volumes de dados.

5.  **API Expressiva:** Oferece uma API intuitiva e poderosa, que combina a facilidade de uso do Pandas com a performance de ferramentas de processamento distribuÃ­do, facilitando a escrita de cÃ³digo limpo e eficiente.

6.  **IntegraÃ§Ã£o com Arrow:** Baseado no Apache Arrow, o Polars garante interoperabilidade eficiente com outras ferramentas do ecossistema de dados, minimizando a cÃ³pia de dados e otimizando o fluxo de trabalho.

---

## ðŸ‡¬ðŸ‡§ High-Speed DataFrames with Polars

This repository explores and demonstrates the use of the **Polars library for high-performance data processing**, focusing on DataFrame operations. Polars is a robust and extremely fast alternative to Pandas, built in Rust, which leverages parallelism and memory efficiency to handle large volumes of data optimally. It is ideal for **exploratory data analysis, feature engineering, and ETL pipelines** that require speed and scalability.

### ðŸŽ¯ Objective

The main objective of this project is to **provide practical examples, benchmarks, and detailed tutorials** for data professionals who wish to migrate to or integrate Polars into their workflows. It will cover everything from the fundamental concepts of DataFrames in Polars to advanced optimization techniques, integration with other libraries, and performance comparison with other tools, with a focus on **efficient I/O operations, complex transformations, and lazy evaluation**.

### âœ¨ Highlights

- **Optimized I/O**: Demonstrations of efficient reading and writing of CSV and Parquet files, leveraging Polars' performance to handle large data volumes.
- **Complex Transformations and Advanced Expressions**: Examples of how to apply sophisticated data transformations, including aggregation, filtering, and creating new columns using Polars' powerful expression syntax.
- **Lazy Evaluation**: Exploration of Polars' lazy evaluation paradigm, which allows for the construction of optimized query plans, resulting in better performance and lower memory consumption.
- **Join and Correlation Operations**: Demonstrations of how to perform join operations between DataFrames and calculate correlations between columns, essential for data analysis and feature engineering.
- **Exceptional Performance**: Polars outperforms other libraries in speed and memory usage for common DataFrame operations, thanks to its Rust implementation and native parallelism.
- **Intuitive API**: Examples showcasing the simplicity and expressiveness of the Polars API, making it easy for Pandas users to transition.
- **Professional Code**: Well-structured code examples, following industry best practices, with a focus on modularity, reusability, and maintainability.
- **Complete Documentation**: Each example is accompanied by detailed documentation, benchmarks, and practical use cases to facilitate understanding and application.

### ðŸ“Š Visualization

![Polars Data Processing Flow](diagrams/polars_data_processing_flow.png)

*Diagrama ilustrativo do fluxo de processamento de dados com Polars, destacando as etapas de ingestÃ£o, transformaÃ§Ã£o e saÃ­da.*


---

## ðŸ› ï¸ Tecnologias Utilizadas / Technologies Used

| Categoria         | Tecnologia      | DescriÃ§Ã£o                                                                 |
| :---------------- | :-------------- | :------------------------------------------------------------------------ |
| **Linguagem**     | Python          | Linguagem principal para desenvolvimento e interface com Polars.          |
| **DataFrames**    | Polars          | Biblioteca de DataFrames de alta performance, construÃ­da em Rust.         |
| **SerializaÃ§Ã£o**  | CSV, Parquet    | Formatos de arquivo suportados para leitura e escrita otimizadas.         |
| **Testes**        | `pytest`        | Framework de testes para validaÃ§Ã£o de funcionalidades e performance.      |
| **DiagramaÃ§Ã£o**   | Mermaid         | Para criaÃ§Ã£o de diagramas de arquitetura e fluxo de dados no README.      |

---

## ðŸ“ Repository Structure

```
polars-high-speed-dataframes/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ polars_demo.py           # LÃ³gica principal com exemplos de uso do Polars
â”œâ”€â”€ data/                        # Dados de exemplo (CSV, Parquet) para benchmarks e testes
â”œâ”€â”€ images/                      # Imagens e grÃ¡ficos para o README e documentaÃ§Ã£o
â”œâ”€â”€ tests/                       # Testes unitÃ¡rios e de integraÃ§Ã£o para as implementaÃ§Ãµes
â”œâ”€â”€ docs/                        # DocumentaÃ§Ã£o adicional, tutoriais e guias de performance
â”œâ”€â”€ scripts/                     # Scripts utilitÃ¡rios para automaÃ§Ã£o e execuÃ§Ã£o de benchmarks
â”œâ”€â”€ requirements.txt             # DependÃªncias Python
â””â”€â”€ README.md                    # Este arquivo
```

---

## ðŸš€ Getting Started

Para comeÃ§ar, clone o repositÃ³rio e explore os diretÃ³rios `src/` e `docs/` para exemplos detalhados e instruÃ§Ãµes de uso. Certifique-se de ter as dependÃªncias necessÃ¡rias instaladas.

### PrÃ©-requisitos

- Python 3.9+
- `pip` (gerenciador de pacotes Python)

### InstalaÃ§Ã£o

```bash
git clone https://github.com/GabrielDemetriosLafis/polars-high-speed-dataframes.git
cd polars-high-speed-dataframes

# Instalar dependÃªncias Python
pip install -r requirements.txt
```

### Exemplo de Uso AvanÃ§ado (Python)

O exemplo abaixo demonstra a inicializaÃ§Ã£o da classe `PolarsProcessor`, a criaÃ§Ã£o de DataFrames, operaÃ§Ãµes de agrupamento e agregaÃ§Ã£o, adiÃ§Ã£o de novas colunas, operaÃ§Ãµes encadeadas, avaliaÃ§Ã£o lazy complexa, joins com outros DataFrames e cÃ¡lculo de correlaÃ§Ã£o. Este cÃ³digo ilustra a flexibilidade e o poder do Polars para manipulaÃ§Ã£o de dados de alta performance.

```python
import polars as pl
from src.polars_demo import PolarsProcessor
import os

if __name__ == "__main__":
    print("=" * 60)
    print("Polars High-Speed DataFrames Demo")
    print("=" * 60)

    processor = PolarsProcessor()

    # Criar um DataFrame de exemplo
    data = {
        "name": ["Alice", "Bob", "Charlie", "David", "Eve", "Frank", "Grace", "Heidi"],
        "age": [25, 30, 35, 28, 40, 22, 32, 45],
        "city": ["New York", "London", "New York", "Paris", "London", "New York", "Paris", "London"],
        "salary": [50000, 70000, 60000, 55000, 80000, 45000, 65000, 90000]
    }
    df = pl.DataFrame(data)
    print("\nOriginal DataFrame:")
    print(df)

    # --- 1. Agrupar e agregar ---
    print("\n--- 1. MÃ©dia salarial por cidade: ---")
    avg_salary_df = processor.group_and_aggregate(df)
    print(avg_salary_df)

    # --- 2. Adicionar coluna de bÃ´nus ---
    print("\n--- 2. DataFrame com bÃ´nus (10%): ---")
    df_with_bonus = processor.add_bonus_column(df, 0.10)
    print(df_with_bonus)

    # --- 3. OperaÃ§Ãµes encadeadas ---
    print("\n--- 3. OperaÃ§Ãµes encadeadas (idade > 25, 5% bÃ´nus): ---")
    chained_df = processor.chain_operations(df, 25, 0.05)
    print(chained_df)

    # --- 4. AvaliaÃ§Ã£o Lazy Complexa ---
    print("\n--- 4. AvaliaÃ§Ã£o Lazy Complexa (idade > 25, avg_salary_city < 60000): ---")
    complex_lazy_df = processor.complex_lazy_evaluation(df, 25, 60000)
    print(complex_lazy_df)

    # --- 5. Join com outro DataFrame ---
    print("\n--- 5. DataFrame apÃ³s join com informaÃ§Ãµes de departamento: ---")
    other_data = {
        "name": ["Alice", "Bob", "Charlie", "David", "Eve"],
        "department": ["HR", "Engineering", "Sales", "Marketing", "Engineering"]
    }
    other_df = pl.DataFrame(other_data)
    joined_df = processor.join_with_another_dataframe(df, other_df, "name")
    print(joined_df)

    # --- 6. Calcular correlaÃ§Ã£o ---
    print("\n--- 6. CorrelaÃ§Ã£o entre idade e salÃ¡rio: ---")
    correlation = processor.calculate_correlation(df, "age", "salary")
    print(f"  CorrelaÃ§Ã£o: {correlation:.2f}")

    # --- 7. Leitura e Escrita de Arquivos (CSV e Parquet) ---
    print("\n--- 7. DemonstraÃ§Ã£o de Leitura e Escrita de Arquivos ---")
    # Criar um arquivo CSV de exemplo
    csv_file = "data/sample.csv"
    df.write_csv(csv_file)
    print(f"  DataFrame salvo em {csv_file}")

    # Ler o arquivo CSV
    read_csv_df = processor.read_csv_file(csv_file)
    print("  DataFrame lido de CSV:")
    print(read_csv_df)

    # Criar um arquivo Parquet de exemplo
    parquet_file = "data/sample.parquet"
    df.write_parquet(parquet_file)
    print(f"  DataFrame salvo em {parquet_file}")

    # Ler o arquivo Parquet
    read_parquet_df = processor.read_parquet_file(parquet_file)
    print("  DataFrame lido de Parquet:")
    print(read_parquet_df)

    # Limpar arquivos gerados
    if os.path.exists(csv_file):
        os.remove(csv_file)
    if os.path.exists(parquet_file):
        os.remove(parquet_file)

    print("\n==================================================")
    print("DemonstraÃ§Ã£o ConcluÃ­da.")
    print("==================================================")
```

---

## ðŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues, enviar pull requests ou sugerir melhorias. Por favor, siga as diretrizes de contribuiÃ§Ã£o.

---

## ðŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

**Autor:** Gabriel Demetrios Lafis  \n**Ano:** 2025